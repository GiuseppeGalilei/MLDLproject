{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWd0bRvgDvpR",
        "outputId": "072b791a-20bc-455b-91c9-7580c6dc963c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MLDLproject'...\n",
            "remote: Enumerating objects: 881, done.\u001b[K\n",
            "remote: Counting objects: 100% (313/313), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 881 (delta 159), reused 142 (delta 75), pack-reused 568\u001b[K\n",
            "Receiving objects: 100% (881/881), 986.08 KiB | 12.03 MiB/s, done.\n",
            "Resolving deltas: 100% (391/391), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b refactor https://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@github.com/GiuseppeGalilei/MLDLproject.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8nJ4Ma3D-rB",
        "outputId": "c76a4f83-1e95-4e6e-a9c8-6300821bbc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MLDLproject\n"
          ]
        }
      ],
      "source": [
        "%cd MLDLproject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bpUPmv4vDtWA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "from models.resnet import ResNet50\n",
        "from utils.datasets import get_datasets\n",
        "from utils.sampling import get_user_groups\n",
        "from utils.reproducibility import make_it_reproducible\n",
        "from feddyn.components import FedDynServer, FedDynClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GvHwqBKjDtWE"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ck0jBYvfrWQ",
        "outputId": "b7d9d77d-1c6d-4b3a-c3b8-6efdda5c7d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.get_device_name(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WpFrqzGPDtWF"
      },
      "outputs": [],
      "source": [
        "seed = 0  # 128, 479"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VoGrYJ0QDtWG"
      },
      "outputs": [],
      "source": [
        "# setting parameters\n",
        "client_number = 50\n",
        "participation_frac = 0.06\n",
        "ROUNDS = 50\n",
        "alpha = 0.01\n",
        "lr = 0.1\n",
        "local_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03KmRLYmDtWH",
        "outputId": "d8c8190a-a17a-473e-ee01-9a17caf6c9ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Communication round:  1\n",
            "Chosen users: [ 8 39 12]\n",
            "Training client 8 ... done! average loss=13.188253164291382\n",
            "Training client 39 ... done! average loss=12.804186180233955\n",
            "Training client 12 ... done! average loss=13.35630688071251\n",
            "Updating server model... done!\n",
            "Evaluating model at round 0 ... done!\n",
            "{'round': 0, 'test_accuracy': 0.1, 'test_avg_loss': nan}\n",
            "Communication round:  2\n",
            "Chosen users: [19 41 12]\n",
            "Training client 19 ... done! average loss=9.918255552649498\n",
            "Training client 41 ... done! average loss=10.150955930352211\n",
            "Training client 12 ... done! average loss=9.969182327389717\n",
            "Updating server model... done!\n",
            "Evaluating model at round 1 ... done!\n",
            "{'round': 1, 'test_accuracy': 0.1, 'test_avg_loss': nan}\n",
            "Communication round:  3\n",
            "Chosen users: [48 30  7]\n",
            "Training client 48 ... done! average loss=9.342511996626854\n",
            "Training client 30 ... done! average loss=9.577558636665344\n",
            "Training client 7 ... done! average loss=9.282390922307968\n",
            "Updating server model... done!\n",
            "Evaluating model at round 2 ... done!\n",
            "{'round': 2, 'test_accuracy': 0.1, 'test_avg_loss': nan}\n",
            "Communication round:  4\n",
            "Chosen users: [41 44 15]\n",
            "Training client 41 ... done! average loss=8.597566545009613\n",
            "Training client 44 ... done! average loss=8.873353570699692\n",
            "Training client 15 ... done! average loss=8.615500003099442\n",
            "Updating server model... done!\n",
            "Evaluating model at round 3 ... done!\n",
            "{'round': 3, 'test_accuracy': 0.1, 'test_avg_loss': nan}\n",
            "Communication round:  5\n",
            "Chosen users: [45 26 36]\n",
            "Training client 45 ... done! average loss=8.147707253694534\n",
            "Training client 26 ... done! average loss=8.524321421980858\n",
            "Training client 36 ... done! average loss=7.9549446403980255\n",
            "Updating server model... done!\n",
            "Evaluating model at round 4 ... done!\n",
            "{'round': 4, 'test_accuracy': 0.1, 'test_avg_loss': nan}\n",
            "Communication round:  6\n",
            "Chosen users: [49 21 46]\n",
            "Training client 49 ... done! average loss=7.5750871151685715\n",
            "Training client 21 ... done! average loss=7.9416666477918625\n",
            "Training client 46 ... done! average loss=7.792979538440704\n",
            "Updating server model... done!\n",
            "Evaluating model at round 5 ... done!\n",
            "{'round': 5, 'test_accuracy': 0.1, 'test_avg_loss': nan}\n",
            "Communication round:  7\n",
            "Chosen users: [ 8  5 25]\n",
            "Training client 8 ... "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a5f21cb48499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mactive_clients_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactive_users\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_server_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mactive_clients_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MLDLproject/feddyn/components.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, server_state_dict, round)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m#                 torch.nn.utils.clip_grad_norm_(parameters=self.model.parameters(), max_norm=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mcur_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    150\u001b[0m                   \u001b[0mdampening\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                   \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnesterov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                   maximize=maximize,)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;31m# update momentum_buffers in state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "metric = []\n",
        "make_it_reproducible(seed)\n",
        "\n",
        "iid = True\n",
        "unbalanced = False\n",
        "norm = \"Batch Norm\"\n",
        "\n",
        "trainset, testset = get_datasets(augmentation=True)\n",
        "\n",
        "# server, reproducibility demanded to the server\n",
        "server = FedDynServer(ResNet50(), alpha, client_number, device, testset, seed)\n",
        "\n",
        "# clients\n",
        "client_model = ResNet50()\n",
        "clients = []\n",
        "user_groups, _ = get_user_groups(trainset, iid=iid, unbalanced=unbalanced, tot_users=client_number)\n",
        "for idx in range(client_number):\n",
        "    clients.append(FedDynClient(client_model, device, lr, alpha, idx, local_epochs, trainset, user_groups[idx]))\n",
        "\n",
        "for round in range(ROUNDS):\n",
        "    print(\"Communication round: \", round+1)\n",
        "    m = max(int(participation_frac*client_number), 1)\n",
        "    active_users = np.random.choice(range(client_number), m, replace=False)\n",
        "    print(f\"Chosen users: {active_users}\")\n",
        "\n",
        "    act_server_state = server.get_server_state()\n",
        "    active_clients_params = []\n",
        "    for idx in active_users:\n",
        "        client_params, metrics = clients[idx].train(act_server_state, round)\n",
        "        active_clients_params.append(client_params)\n",
        "\n",
        "    server.update_model(active_clients_params)\n",
        "    server.evaluate(round)\n",
        "    print(server.get_test_metrics()[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBRXL4YSOIU6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "federated_dyn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
